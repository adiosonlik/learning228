{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import models as vision_models\n",
    "import timm\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import decode_image\n",
    "from pathlib import Path\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "source_dir = r\"journey-springfield\\train\"\n",
    "target_dir = os.path.join(os.path.dirname(source_dir), \"dataset\", \"images\")\n",
    "csv_path = os.path.join(os.path.dirname(source_dir), \"dataset\", \"labels.csv\")\n",
    "\n",
    "# Создаем целевую директорию, если её нет\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Массив для хранения данных\n",
    "data = []\n",
    "\n",
    "# Перебираем классы в исходной директории\n",
    "for class_name in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path): \n",
    "        continue\n",
    "\n",
    "    # Перебираем изображения в каждом классе\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        new_img_path = os.path.join(target_dir, img_name)\n",
    "\n",
    "        # Проверяем, существует ли уже файл с таким именем\n",
    "        if os.path.exists(new_img_path):\n",
    "            base, ext = os.path.splitext(img_name)\n",
    "            new_img_name = f\"{base}_{class_name}{ext}\"\n",
    "            new_img_path = os.path.join(target_dir, new_img_name)\n",
    "\n",
    "        # Перемещаем изображение в целевую директорию\n",
    "        shutil.move(img_path, new_img_path)\n",
    "\n",
    "        # Добавляем путь к изображению и класс в список\n",
    "        rel_path = os.path.relpath(new_img_path, os.path.dirname(csv_path))\n",
    "        data.append([rel_path, class_name])\n",
    "\n",
    "# Создаем DataFrame и сохраняем его в CSV\n",
    "df = pd.DataFrame(data, columns=[\"image_path\", \"class\"])\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Готово! Все изображения перемещены в {target_dir}, CSV создан по пути {csv_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "data = pd.read_csv(r'journey-springfield\\dataset\\labels.csv')\n",
    "data['class_id'] = le1.fit_transform(data['class'])\n",
    "data['class_id'] = data['class_id'].astype('int64')\n",
    "train, val = train_test_split(data, test_size=0.15, random_state=1, stratify=data['class'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "\n",
    "print(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = r'journey-springfield\\dataset'\n",
    "data['unified_class'] = data['class']\n",
    "train['unified_class'] = train['class']\n",
    "train = train.drop('class',axis = 1)\n",
    "val['unified_class'] = val['class']\n",
    "val = val.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = vision_models.efficientnet_b1(vision_models.EfficientNet_B1_Weights.DEFAULT)\n",
    "        self.model.classifier[1] = torch.nn.Linear(self.model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        inputs, _ = batch\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, path_to_images: Path, transforms: tt.Compose) -> None:\n",
    "        self.df = dataframe\n",
    "        self.path_to_images = path_to_images\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # print(row)\n",
    "        image = Image.open(self.path_to_images + '\\\\' + row[\"image_path\"]).convert('RGB')\n",
    "        # print(image)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        return image, row[\"class_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "img = read_image(images_path +'\\\\'+ data.iloc[idx][\"image_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_size = 244\n",
    "# Imagenet mean and standard (are calculated from all of images)\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = tt.Compose([\n",
    "    tt.Resize((int(rescale_size * 1.25), int(rescale_size * 1.25))),\n",
    "    tt.RandomCrop(rescale_size),\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "val_transform = tt.Compose([\n",
    "    tt.Resize((int(rescale_size * 1.05), int(rescale_size * 1.05))),\n",
    "    tt.CenterCrop(rescale_size),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "train_dataset = SimpDataset(train, images_path, transforms=train_transform)\n",
    "val_dataset = SimpDataset(val, images_path, transforms=val_transform)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, num_workers=0, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=64, num_workers=0, shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64,  shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet(num_classes=data[\"unified_class\"].nunique()).to(device)\n",
    "\n",
    "\n",
    "# Инициализируем функцию потерь (loss/criterion), а так же оптимизатор, который будет регулировать обновление весов нашей модели\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Переменные для визуализации метрик и функции потерь\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Для удобства оценивать качество модели будем той же метрику, что на лидерборде - F1 score\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "# Определим, сколько раз мы пройдёмся по всему датасету, прежде, чем закончим обучение модели и выберем лучшую версию\n",
    "num_epochs = 25\n",
    "\n",
    "# Шаговое уменьшение (StepLR)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Каждые 5 эпох уменьшать lr в 10 раз\n",
    "\n",
    "# Напишем свой train_loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_true = []\n",
    "    train_pred = []\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model((inputs, labels))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "\n",
    "    # валидационный цикл, когда мы оцениваем качество работы модели на отложенной выборке\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model((inputs, labels))\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_true.extend(labels.cpu().numpy())\n",
    "            val_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_true, val_pred, average='macro')\n",
    "    val_losses.append(val_running_loss / len(valid_dataloader))\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # если получившаяся модель лучше предыдущей, сохраним чекпоинт\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'New best model saved with F1: {best_val_f1:.4f}')\n",
    "\n",
    "\n",
    "    # выведем в консоль получившиеся результаты на отдельной эпохе\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Val Loss: {val_losses[-1]:.4f}, Val F1: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(r\"journey-springfield\\sample_submission.csv\")\n",
    "sample['image_name'] = r'journey-springfield/testset/'+sample['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        return image, image_path\n",
    "\n",
    "\n",
    "# Тут важно не ошибиться и не использовать тренировочные трансформы\n",
    "infer_transform = tt.Compose([\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.RandomRotation((-5, 5)),\n",
    "    tt.Resize((int(244 * 1.25), int(244 * 1.25))),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Найдем все тестовые картинки\n",
    "test_image_paths = sample.image_name.tolist()\n",
    "\n",
    "infer_dataset = InferenceDataset(test_image_paths, transforms=infer_transform)\n",
    "infer_dataloader = DataLoader(infer_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "best_model_path = r'best_model.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Не забудем перевести модель в режим предсказания, а не обучения.\n",
    "model.eval()\n",
    "\n",
    "# Для ускорения инференса будем подавать в модель картинки батчами (по несколько картинок за раз) и сохраним предсказанные метки классов.\n",
    "results = []\n",
    "for images, image_names in tqdm(infer_dataloader):\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model((images, None)) #для не хагина\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        results.append(preds[0])\n",
    "\n",
    "\n",
    "# Для удобства объединим все пары \"имя файла - предсказанный класс\" в датафрейм (таблицу) с колонками image_name, predicted_class\n",
    "sample['predicted_class'] = results\n",
    "\n",
    "# Вывод DataFrame\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Expected'] = le1.inverse_transform(sample['predicted_class'])\n",
    "sample.drop(['image_name','predicted_class'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('submit.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
